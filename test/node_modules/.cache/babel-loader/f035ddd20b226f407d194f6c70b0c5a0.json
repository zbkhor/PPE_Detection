{"remainingRequest":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\babel-loader\\lib\\index.js!C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\cache-loader\\dist\\cjs.js??ref--0-0!C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\vue-loader\\lib\\index.js??vue-loader-options!C:\\PPE_Detection\\tfjs-vue-example\\src\\App.vue?vue&type=script&lang=js&","dependencies":[{"path":"C:\\PPE_Detection\\tfjs-vue-example\\src\\App.vue","mtime":1657615919664},{"path":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1657169709851},{"path":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\babel-loader\\lib\\index.js","mtime":1657169710845},{"path":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1657169709851},{"path":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\vue-loader\\lib\\index.js","mtime":1657169712686}],"contextDependencies":[],"result":["import \"core-js/modules/web.dom.iterable\";\nimport \"core-js/modules/es6.string.iterator\";\nimport _typeof from \"C:\\\\PPE_Detection\\\\tfjs-vue-example\\\\node_modules\\\\@babel\\\\runtime-corejs2/helpers/esm/typeof\";\nimport \"regenerator-runtime/runtime\";\nimport _asyncToGenerator from \"C:\\\\PPE_Detection\\\\tfjs-vue-example\\\\node_modules\\\\@babel\\\\runtime-corejs2/helpers/esm/asyncToGenerator\";\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\nvar boxes;\nimport * as tf from '@tensorflow/tfjs';\nimport { loadGraphModel } from '@tensorflow/tfjs-converter';\nimport { drawRect } from \"./utilities\";\nvar MODEL_URL = 'https://raw.githubusercontent.com/zbkhor/ExportModel/main/model/model.json';\nexport default {\n  name: 'app',\n  data: function data() {\n    return {\n      // store the promises of initialization\n      streamPromise: null,\n      modelPromise: null,\n      // control the UI visibilities\n      isVideoStreamReady: false,\n      isModelReady: false,\n      initFailMessage: '',\n      // tfjs model related\n      model: null,\n      videoRatio: 1,\n      resultWidth: 0,\n      resultHeight: 0\n    };\n  },\n  methods: {\n    initWebcamStream: function initWebcamStream() {\n      var _this = this;\n\n      // if the browser supports mediaDevices.getUserMedia API\n      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n        return navigator.mediaDevices.getUserMedia({\n          audio: false,\n          // don't capture audio\n          video: {\n            facingMode: 'environment' // use the rear camera if there is\n\n          }\n        }).then(function (stream) {\n          // set <video> source as the webcam input\n          var video = _this.$refs.video;\n\n          try {\n            video.srcObject = stream;\n          } catch (error) {\n            // support older browsers\n            video.src = URL.createObjectURL(stream);\n          }\n          /*\r\n            model.detect uses tf.fromPixels to create tensors.\r\n            tf.fromPixels api will get the <video> size from the width and height attributes,\r\n              which means <video> width and height attributes needs to be set before called model.detect\r\n              To make the <video> responsive, I get the initial video ratio when it's loaded (onloadedmetadata)\r\n            Then addEventListener on resize, which will adjust the size but remain the ratio\r\n            At last, resolve the Promise.\r\n          */\n\n\n          return new Promise(function (resolve, reject) {\n            // when video is loaded\n            video.onloadedmetadata = function () {\n              // calculate the video ratio\n              _this.videoRatio = video.offsetHeight / video.offsetWidth; // add event listener on resize to reset the <video> and <canvas> sizes\n\n              window.addEventListener('resize', _this.setResultSize); // set the initial size\n\n              _this.setResultSize();\n\n              _this.isVideoStreamReady = true;\n              console.log('webcam stream initialized');\n              resolve();\n            };\n          });\n        }).catch(function (error) {\n          console.log('failed to initialize webcam stream', error);\n          throw error;\n        });\n      } else {\n        return Promise.reject(new Error('Your browser does not support mediaDevices.getUserMedia API'));\n      }\n    },\n    setResultSize: function setResultSize() {\n      // get the current browser window size\n      var clientWidth = document.documentElement.clientWidth; // set max width as 600\n\n      this.resultWidth = Math.min(640, clientWidth); // set the height according to the video ratio\n\n      this.resultHeight = 640; // set <video> width and height\n\n      /*\r\n        Doesn't use vue binding :width and :height,\r\n          because the initial value of resultWidth and resultHeight\r\n          will affect the ratio got from the initWebcamStream()\r\n      */\n\n      var video = this.$refs.video;\n      video.width = this.resultWidth;\n      video.height = this.resultHeight;\n    },\n    loadCustomModel: function loadCustomModel() {\n      var _this2 = this;\n\n      this.isModelReady = false; // load the model with loadGraphModel\n\n      return loadGraphModel(MODEL_URL).then(function (model) {\n        _this2.model = model;\n        _this2.isModelReady = true;\n        console.log('model loaded: ', model);\n      }).catch(function (error) {\n        console.log('failed to load the model', error);\n        throw error;\n      });\n    },\n    detectObjects: function () {\n      var _detectObjects = _asyncToGenerator(\n      /*#__PURE__*/\n      regeneratorRuntime.mark(function _callee() {\n        var _this3 = this;\n\n        var img, resized, casted, expanded, obj, i, boxes, notsure, scores, classes, ctx;\n        return regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (this.isModelReady) {\n                  _context.next = 2;\n                  break;\n                }\n\n                return _context.abrupt(\"return\");\n\n              case 2:\n                img = tf.browser.fromPixels(this.$refs.video);\n                resized = tf.image.resizeBilinear(img, [640, 640]);\n                casted = resized.cast('int32');\n                expanded = casted.expandDims(0);\n                _context.next = 8;\n                return this.model.executeAsync(expanded);\n\n              case 8:\n                obj = _context.sent;\n                console.log(obj[1].array());\n                console.log(obj[4].array()); //check the size and assign to correct tensor\n\n                i = 0;\n\n              case 12:\n                if (!(i < 8)) {\n                  _context.next = 39;\n                  break;\n                }\n\n                console.log('no');\n\n                if (!(obj[i].size == 400 && obj[i].shape.length == 3)) {\n                  _context.next = 21;\n                  break;\n                }\n\n                _context.next = 17;\n                return obj[i].array();\n\n              case 17:\n                boxes = _context.sent;\n                console.log(boxes);\n                _context.next = 36;\n                break;\n\n              case 21:\n                if (!(obj[i].size == 100 && obj[i].shape.length == 2)) {\n                  _context.next = 36;\n                  break;\n                }\n\n                _context.next = 24;\n                return obj[i].array();\n\n              case 24:\n                notsure = _context.sent;\n                console.log();\n\n                if (!(notsure[0][0] < 1)) {\n                  _context.next = 32;\n                  break;\n                }\n\n                _context.next = 29;\n                return obj[i].array();\n\n              case 29:\n                scores = _context.sent;\n                _context.next = 36;\n                break;\n\n              case 32:\n                if (!(notsure[0][0] >= 1)) {\n                  _context.next = 36;\n                  break;\n                }\n\n                _context.next = 35;\n                return obj[i].array();\n\n              case 35:\n                classes = _context.sent;\n\n              case 36:\n                i++;\n                _context.next = 12;\n                break;\n\n              case 39:\n                // const boxes = await obj[3].array()\n                // const classes = await obj[4].array()\n                // const scores = await obj[1].array()\n                console.log(boxes);\n                console.log(_typeof(obj[3].size));\n                console.log(obj[3].shape.length);\n                console.log(obj[4].size);\n                console.log(obj[4].shape.length);\n                console.log(obj[1].size);\n                console.log(obj[1].shape.length); // this.renderPredictionBoxes(predictions[0].dataSync(), predictions[1].dataSync(), predictions[2].dataSync(), predictions[3].dataSync())\n\n                ctx = this.$refs.canvas.getContext(\"2d\");\n                requestAnimationFrame(function () {\n                  drawRect(boxes[0], classes[0], scores[0], 0.5, _this3.$refs.video.width, _this3.$refs.video.height, ctx);\n                });\n                tf.dispose(img);\n                tf.dispose(resized);\n                tf.dispose(casted);\n                tf.dispose(expanded);\n                tf.dispose(obj);\n                ctx.clearRect(0, 0, this.$refs.canvas.width, this.$refs.canvas.height);\n                console.log('cleared');\n\n              case 55:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function detectObjects() {\n        return _detectObjects.apply(this, arguments);\n      }\n\n      return detectObjects;\n    }(),\n    loadModelAndDetection: function loadModelAndDetection() {\n      var _this4 = this;\n\n      this.modelPromise = this.loadCustomModel(); // wait for both stream and model promise finished then start detecting objects\n\n      Promise.all([this.streamPromise, this.modelPromise]).then(function () {\n        setInterval(_this4.detectObjects, 1000);\n      }).catch(function (error) {\n        console.log('Failed to init stream and/or model: ');\n        _this4.initFailMessage = error;\n      });\n    }\n  },\n  mounted: function mounted() {\n    this.streamPromise = this.initWebcamStream();\n    this.loadModelAndDetection();\n  }\n};",{"version":3,"sources":["App.vue"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;AAcA,IAAA,KAAA;AACA,OAAA,KAAA,EAAA,MAAA,kBAAA;AACA,SAAA,cAAA,QAAA,4BAAA;AACA,SAAA,QAAA;AACA,IAAA,SAAA,GAAA,4EAAA;AAEA,eAAA;AACA,EAAA,IAAA,EAAA,KADA;AAGA,EAAA,IAHA,kBAGA;AACA,WAAA;AACA;AACA,MAAA,aAAA,EAAA,IAFA;AAGA,MAAA,YAAA,EAAA,IAHA;AAKA;AACA,MAAA,kBAAA,EAAA,KANA;AAOA,MAAA,YAAA,EAAA,KAPA;AAQA,MAAA,eAAA,EAAA,EARA;AAUA;AACA,MAAA,KAAA,EAAA,IAXA;AAaA,MAAA,UAAA,EAAA,CAbA;AAcA,MAAA,WAAA,EAAA,CAdA;AAeA,MAAA,YAAA,EAAA;AAfA,KAAA;AAiBA,GArBA;AAuBA,EAAA,OAAA,EAAA;AACA,IAAA,gBADA,8BACA;AAAA;;AACA;AACA,UAAA,SAAA,CAAA,YAAA,IAAA,SAAA,CAAA,YAAA,CAAA,YAAA,EAAA;AACA,eAAA,SAAA,CAAA,YAAA,CAAA,YAAA,CAAA;AACA,UAAA,KAAA,EAAA,KADA;AACA;AACA,UAAA,KAAA,EAAA;AAAA,YAAA,UAAA,EAAA,aAAA,CAAA;;AAAA;AAFA,SAAA,EAIA,IAJA,CAIA,UAAA,MAAA,EAAA;AACA;AACA,cAAA,KAAA,GAAA,KAAA,CAAA,KAAA,CAAA,KAAA;;AACA,cAAA;AACA,YAAA,KAAA,CAAA,SAAA,GAAA,MAAA;AACA,WAFA,CAEA,OAAA,KAAA,EAAA;AACA;AACA,YAAA,KAAA,CAAA,GAAA,GAAA,GAAA,CAAA,eAAA,CAAA,MAAA,CAAA;AACA;AAEA;;;;;;;;;;AASA,iBAAA,IAAA,OAAA,CAAA,UAAA,OAAA,EAAA,MAAA,EAAA;AACA;AACA,YAAA,KAAA,CAAA,gBAAA,GAAA,YAAA;AACA;AACA,cAAA,KAAA,CAAA,UAAA,GAAA,KAAA,CAAA,YAAA,GAAA,KAAA,CAAA,WAAA,CAFA,CAGA;;AACA,cAAA,MAAA,CAAA,gBAAA,CAAA,QAAA,EAAA,KAAA,CAAA,aAAA,EAJA,CAKA;;AACA,cAAA,KAAA,CAAA,aAAA;;AAEA,cAAA,KAAA,CAAA,kBAAA,GAAA,IAAA;AACA,cAAA,OAAA,CAAA,GAAA,CAAA,2BAAA;AACA,cAAA,OAAA;AACA,aAXA;AAYA,WAdA,CAAA;AAeA,SAtCA,EAuCA,KAvCA,CAuCA,UAAA,KAAA,EAAA;AACA,UAAA,OAAA,CAAA,GAAA,CAAA,oCAAA,EAAA,KAAA;AACA,gBAAA,KAAA;AACA,SA1CA,CAAA;AA2CA,OA5CA,MA4CA;AACA,eAAA,OAAA,CAAA,MAAA,CAAA,IAAA,KAAA,CAAA,6DAAA,CAAA,CAAA;AACA;AACA,KAlDA;AAoDA,IAAA,aApDA,2BAoDA;AACA;AACA,UAAA,WAAA,GAAA,QAAA,CAAA,eAAA,CAAA,WAAA,CAFA,CAIA;;AACA,WAAA,WAAA,GAAA,IAAA,CAAA,GAAA,CAAA,GAAA,EAAA,WAAA,CAAA,CALA,CAMA;;AACA,WAAA,YAAA,GAAA,GAAA,CAPA,CASA;;AACA;;;;;;AAKA,UAAA,KAAA,GAAA,KAAA,KAAA,CAAA,KAAA;AACA,MAAA,KAAA,CAAA,KAAA,GAAA,KAAA,WAAA;AACA,MAAA,KAAA,CAAA,MAAA,GAAA,KAAA,YAAA;AACA,KAtEA;AAwEA,IAAA,eAxEA,6BAwEA;AAAA;;AACA,WAAA,YAAA,GAAA,KAAA,CADA,CAGA;;AACA,aAAA,cAAA,CAAA,SAAA,CAAA,CACA,IADA,CACA,UAAA,KAAA,EAAA;AACA,QAAA,MAAA,CAAA,KAAA,GAAA,KAAA;AACA,QAAA,MAAA,CAAA,YAAA,GAAA,IAAA;AACA,QAAA,OAAA,CAAA,GAAA,CAAA,gBAAA,EAAA,KAAA;AACA,OALA,EAMA,KANA,CAMA,UAAA,KAAA,EAAA;AACA,QAAA,OAAA,CAAA,GAAA,CAAA,0BAAA,EAAA,KAAA;AACA,cAAA,KAAA;AACA,OATA,CAAA;AAUA,KAtFA;AAwFA,IAAA,aAxFA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAyFA,KAAA,YAzFA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AA2FA,gBAAA,GA3FA,GA2FA,EAAA,CAAA,OAAA,CAAA,UAAA,CAAA,KAAA,KAAA,CAAA,KAAA,CA3FA;AA4FA,gBAAA,OA5FA,GA4FA,EAAA,CAAA,KAAA,CAAA,cAAA,CAAA,GAAA,EAAA,CAAA,GAAA,EAAA,GAAA,CAAA,CA5FA;AA6FA,gBAAA,MA7FA,GA6FA,OAAA,CAAA,IAAA,CAAA,OAAA,CA7FA;AA8FA,gBAAA,QA9FA,GA8FA,MAAA,CAAA,UAAA,CAAA,CAAA,CA9FA;AAAA;AAAA,uBA+FA,KAAA,KAAA,CAAA,YAAA,CAAA,QAAA,CA/FA;;AAAA;AA+FA,gBAAA,GA/FA;AAgGA,gBAAA,OAAA,CAAA,GAAA,CAAA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,EAAA;AACA,gBAAA,OAAA,CAAA,GAAA,CAAA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,EAAA,EAjGA,CAkGA;;AACA,gBAAA,CAnGA,GAmGA,CAnGA;;AAAA;AAAA,sBAmGA,CAAA,GAAA,CAnGA;AAAA;AAAA;AAAA;;AAoGA,gBAAA,OAAA,CAAA,GAAA,CAAA,IAAA;;AApGA,sBAqGA,GAAA,CAAA,CAAA,CAAA,CAAA,IAAA,IAAA,GAAA,IAAA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,MAAA,IAAA,CArGA;AAAA;AAAA;AAAA;;AAAA;AAAA,uBAuGA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,EAvGA;;AAAA;AAuGA,gBAAA,KAvGA;AAwGA,gBAAA,OAAA,CAAA,GAAA,CAAA,KAAA;AAxGA;AAAA;;AAAA;AAAA,sBA0GA,GAAA,CAAA,CAAA,CAAA,CAAA,IAAA,IAAA,GAAA,IAAA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,MAAA,IAAA,CA1GA;AAAA;AAAA;AAAA;;AAAA;AAAA,uBA4GA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,EA5GA;;AAAA;AA4GA,gBAAA,OA5GA;AA6GA,gBAAA,OAAA,CAAA,GAAA;;AA7GA,sBA+GA,OAAA,CAAA,CAAA,CAAA,CAAA,CAAA,IAAA,CA/GA;AAAA;AAAA;AAAA;;AAAA;AAAA,uBAiHA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,EAjHA;;AAAA;AAiHA,gBAAA,MAjHA;AAAA;AAAA;;AAAA;AAAA,sBAkHA,OAAA,CAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAlHA;AAAA;AAAA;AAAA;;AAAA;AAAA,uBAmHA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,EAnHA;;AAAA;AAmHA,gBAAA,OAnHA;;AAAA;AAmGA,gBAAA,CAAA,EAnGA;AAAA;AAAA;;AAAA;AAwHA;AACA;AACA;AACA,gBAAA,OAAA,CAAA,GAAA,CAAA,KAAA;AACA,gBAAA,OAAA,CAAA,GAAA,SAAA,GAAA,CAAA,CAAA,CAAA,CAAA,IAAA;AACA,gBAAA,OAAA,CAAA,GAAA,CAAA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,MAAA;AACA,gBAAA,OAAA,CAAA,GAAA,CAAA,GAAA,CAAA,CAAA,CAAA,CAAA,IAAA;AACA,gBAAA,OAAA,CAAA,GAAA,CAAA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,MAAA;AACA,gBAAA,OAAA,CAAA,GAAA,CAAA,GAAA,CAAA,CAAA,CAAA,CAAA,IAAA;AACA,gBAAA,OAAA,CAAA,GAAA,CAAA,GAAA,CAAA,CAAA,CAAA,CAAA,KAAA,CAAA,MAAA,EAjIA,CAmIA;;AACA,gBAAA,GApIA,GAoIA,KAAA,KAAA,CAAA,MAAA,CAAA,UAAA,CAAA,IAAA,CApIA;AAqIA,gBAAA,qBAAA,CAAA,YAAA;AAAA,kBAAA,QAAA,CAAA,KAAA,CAAA,CAAA,CAAA,EAAA,OAAA,CAAA,CAAA,CAAA,EAAA,MAAA,CAAA,CAAA,CAAA,EAAA,GAAA,EAAA,MAAA,CAAA,KAAA,CAAA,KAAA,CAAA,KAAA,EAAA,MAAA,CAAA,KAAA,CAAA,KAAA,CAAA,MAAA,EAAA,GAAA,CAAA;AAAA,iBAAA,CAAA;AAEA,gBAAA,EAAA,CAAA,OAAA,CAAA,GAAA;AACA,gBAAA,EAAA,CAAA,OAAA,CAAA,OAAA;AACA,gBAAA,EAAA,CAAA,OAAA,CAAA,MAAA;AACA,gBAAA,EAAA,CAAA,OAAA,CAAA,QAAA;AACA,gBAAA,EAAA,CAAA,OAAA,CAAA,GAAA;AACA,gBAAA,GAAA,CAAA,SAAA,CAAA,CAAA,EAAA,CAAA,EAAA,KAAA,KAAA,CAAA,MAAA,CAAA,KAAA,EAAA,KAAA,KAAA,CAAA,MAAA,CAAA,MAAA;AACA,gBAAA,OAAA,CAAA,GAAA,CAAA,SAAA;;AA7IA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAgJA,IAAA,qBAhJA,mCAgJA;AAAA;;AACA,WAAA,YAAA,GAAA,KAAA,eAAA,EAAA,CADA,CAGA;;AACA,MAAA,OAAA,CAAA,GAAA,CAAA,CAAA,KAAA,aAAA,EAAA,KAAA,YAAA,CAAA,EACA,IADA,CACA,YAAA;AACA,QAAA,WAAA,CAAA,MAAA,CAAA,aAAA,EAAA,IAAA,CAAA;AACA,OAHA,EAGA,KAHA,CAGA,UAAA,KAAA,EAAA;AACA,QAAA,OAAA,CAAA,GAAA,CAAA,sCAAA;AACA,QAAA,MAAA,CAAA,eAAA,GAAA,KAAA;AACA,OANA;AAOA;AA3JA,GAvBA;AAuLA,EAAA,OAvLA,qBAuLA;AACA,SAAA,aAAA,GAAA,KAAA,gBAAA,EAAA;AACA,SAAA,qBAAA;AAEA;AA3LA,CAAA","sourcesContent":["<template>\r\n  <div id=\"app\">\r\n    <h3 v-if=\"!isVideoStreamReady && !initFailMessage\">Initializing webcam stream ...</h3>\r\n    <h3 v-if=\"!isModelReady && !initFailMessage\">loading model ...</h3>\r\n    <h3 v-if=\"initFailMessage\">Failed to init stream and/or model - {{ initFailMessage }}</h3>\r\n\r\n    <div class=\"resultFrame\">\r\n      <video ref=\"video\" autoplay></video>\r\n      <canvas ref=\"canvas\" :width=\"resultWidth\" :height=\"resultHeight\"></canvas>\r\n    </div>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\nvar boxes;\r\nimport * as tf from '@tensorflow/tfjs'\r\nimport { loadGraphModel } from '@tensorflow/tfjs-converter'\r\nimport {drawRect} from \"./utilities\"; \r\nconst MODEL_URL = 'https://raw.githubusercontent.com/zbkhor/ExportModel/main/model/model.json'\r\n\r\nexport default {\r\n  name: 'app',\r\n\r\n  data () {\r\n    return {\r\n      // store the promises of initialization\r\n      streamPromise: null,\r\n      modelPromise: null,\r\n\r\n      // control the UI visibilities\r\n      isVideoStreamReady: false,\r\n      isModelReady: false,\r\n      initFailMessage: '',\r\n\r\n      // tfjs model related\r\n      model: null,\r\n\r\n      videoRatio: 1,\r\n      resultWidth: 0,\r\n      resultHeight: 0\r\n    }\r\n  },\r\n\r\n  methods: {\r\n    initWebcamStream () {\r\n      // if the browser supports mediaDevices.getUserMedia API\r\n      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\r\n        return navigator.mediaDevices.getUserMedia({\r\n          audio: false, // don't capture audio\r\n          video: { facingMode: 'environment' } // use the rear camera if there is\r\n        })\r\n          .then(stream => {\r\n            // set <video> source as the webcam input\r\n            let video = this.$refs.video\r\n            try {\r\n              video.srcObject = stream\r\n            } catch (error) {\r\n              // support older browsers\r\n              video.src = URL.createObjectURL(stream)\r\n            }\r\n\r\n            /*\r\n              model.detect uses tf.fromPixels to create tensors.\r\n              tf.fromPixels api will get the <video> size from the width and height attributes,\r\n                which means <video> width and height attributes needs to be set before called model.detect\r\n\r\n              To make the <video> responsive, I get the initial video ratio when it's loaded (onloadedmetadata)\r\n              Then addEventListener on resize, which will adjust the size but remain the ratio\r\n              At last, resolve the Promise.\r\n            */\r\n            return new Promise((resolve, reject) => {\r\n              // when video is loaded\r\n              video.onloadedmetadata = () => {\r\n                // calculate the video ratio\r\n                this.videoRatio = video.offsetHeight / video.offsetWidth\r\n                // add event listener on resize to reset the <video> and <canvas> sizes\r\n                window.addEventListener('resize', this.setResultSize)\r\n                // set the initial size\r\n                this.setResultSize()\r\n\r\n                this.isVideoStreamReady = true\r\n                console.log('webcam stream initialized')\r\n                resolve()\r\n              }\r\n            })\r\n          })\r\n          .catch(error => {\r\n            console.log('failed to initialize webcam stream', error)\r\n            throw (error)\r\n          })\r\n      } else {\r\n        return Promise.reject(new Error('Your browser does not support mediaDevices.getUserMedia API'))\r\n      }\r\n    },\r\n    \r\n    setResultSize () {\r\n      // get the current browser window size\r\n      let clientWidth = document.documentElement.clientWidth\r\n\r\n      // set max width as 600\r\n      this.resultWidth = Math.min(640, clientWidth)\r\n      // set the height according to the video ratio\r\n      this.resultHeight = 640\r\n\r\n      // set <video> width and height\r\n      /*\r\n        Doesn't use vue binding :width and :height,\r\n          because the initial value of resultWidth and resultHeight\r\n          will affect the ratio got from the initWebcamStream()\r\n      */\r\n      let video = this.$refs.video\r\n      video.width = this.resultWidth\r\n      video.height = this.resultHeight\r\n    },\r\n\r\n    loadCustomModel () {\r\n      this.isModelReady = false\r\n\r\n      // load the model with loadGraphModel\r\n      return loadGraphModel(MODEL_URL)\r\n        .then((model) => {\r\n          this.model = model\r\n          this.isModelReady = true\r\n          console.log('model loaded: ', model)\r\n        })\r\n        .catch((error) => {\r\n          console.log('failed to load the model', error)\r\n          throw (error)\r\n        })\r\n    },\r\n    \r\n    async detectObjects () {\r\n      if (!this.isModelReady) return\r\n\r\n      const img = tf.browser.fromPixels(this.$refs.video)\r\n      const resized = tf.image.resizeBilinear(img, [640,640])\r\n      const casted = resized.cast('int32')\r\n      const expanded = casted.expandDims(0)\r\n      const obj = await this.model.executeAsync(expanded)\r\n      console.log(obj[1].array()) \r\n      console.log(obj[4].array())\r\n      //check the size and assign to correct tensor\r\n      for(let i = 0;i <8; i++){\r\n       console.log('no')\r\n       if (obj[i].size==400 && obj[i].shape.length==3){\r\n     \r\n        var boxes = await obj[i].array()\r\n        console.log(boxes)\r\n       \r\n       }else if (obj[i].size==100 && obj[i].shape.length==2){\r\n         \r\n          var notsure = await obj[i].array()\r\n          console.log()\r\n        \r\n          if (notsure[0][0] < 1){\r\n           \r\n           var scores = await obj[i].array()\r\n          }else if (notsure[0][0] >=1){\r\n            var classes = await obj[i].array()\r\n          }\r\n       }  \r\n      }\r\n      \r\n      // const boxes = await obj[3].array()\r\n      // const classes = await obj[4].array()\r\n      // const scores = await obj[1].array()\r\n      console.log(boxes)\r\n      console.log(typeof obj[3].size)\r\n      console.log(obj[3].shape.length)\r\n      console.log(obj[4].size)\r\n      console.log(obj[4].shape.length)\r\n      console.log(obj[1].size)\r\n      console.log(obj[1].shape.length)\r\n      \r\n      // this.renderPredictionBoxes(predictions[0].dataSync(), predictions[1].dataSync(), predictions[2].dataSync(), predictions[3].dataSync())\r\n      const ctx = this.$refs.canvas.getContext(\"2d\");\r\n      requestAnimationFrame(()=>{drawRect(boxes[0], classes[0], scores[0], 0.5, this.$refs.video.width, this.$refs.video.height, ctx)}); \r\n\r\n      tf.dispose(img)\r\n      tf.dispose(resized)\r\n      tf.dispose(casted)\r\n      tf.dispose(expanded)\r\n      tf.dispose(obj)\r\n      ctx.clearRect(0, 0, this.$refs.canvas.width, this.$refs.canvas.height);\r\n      console.log('cleared')\r\n    },\r\n\r\n    loadModelAndDetection () {\r\n      this.modelPromise = this.loadCustomModel()\r\n\r\n      // wait for both stream and model promise finished then start detecting objects\r\n      Promise.all([this.streamPromise, this.modelPromise])\r\n        .then(() => {\r\n          setInterval(this.detectObjects,1000)\r\n        }).catch((error) => {\r\n          console.log('Failed to init stream and/or model: ')\r\n          this.initFailMessage = error\r\n        })\r\n    },\r\n\r\n\r\n  },\r\n\r\n  mounted () {\r\n    this.streamPromise = this.initWebcamStream()\r\n    this.loadModelAndDetection()\r\n    \r\n  }\r\n}\r\n</script>\r\n\r\n<style lang=\"scss\">\r\nbody {\r\n  margin: 0;\r\n}\r\n\r\n.resultFrame {\r\n  display: grid;\r\n\r\n  video {\r\n    grid-area: 1 / 8 / 2 / 8;\r\n  }\r\n  canvas {\r\n    grid-area: 1 / 8 / 2 / 8;\r\n  }\r\n}\r\n</style>\r\n"],"sourceRoot":"src"}]}