{"remainingRequest":"C:\\PPE_Detection\\test\\node_modules\\thread-loader\\dist\\cjs.js!C:\\PPE_Detection\\test\\node_modules\\babel-loader\\lib\\index.js!C:\\PPE_Detection\\test\\node_modules\\cache-loader\\dist\\cjs.js??ref--1-0!C:\\PPE_Detection\\test\\node_modules\\vue-loader\\lib\\index.js??vue-loader-options!C:\\PPE_Detection\\test\\src\\Home.vue?vue&type=script&lang=js&","dependencies":[{"path":"C:\\PPE_Detection\\test\\src\\Home.vue","mtime":1657696264014},{"path":"C:\\PPE_Detection\\test\\babel.config.js","mtime":1656468554132},{"path":"C:\\PPE_Detection\\test\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1657695287597},{"path":"C:\\PPE_Detection\\test\\node_modules\\thread-loader\\dist\\cjs.js","mtime":1657695283903},{"path":"C:\\PPE_Detection\\test\\node_modules\\babel-loader\\lib\\index.js","mtime":1657695287786},{"path":"C:\\PPE_Detection\\test\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1657695287597},{"path":"C:\\PPE_Detection\\test\\node_modules\\vue-loader\\lib\\index.js","mtime":1657695283812}],"contextDependencies":[],"result":[{"type":"Buffer","data":"base64:import "core-js/modules/es.error.cause.js";
var boxes;
import * as tf from '@tensorflow/tfjs';
import { loadGraphModel } from '@tensorflow/tfjs-converter';
import { drawRect } from "./utilities";
const MODEL_URL = 'https://raw.githubusercontent.com/zbkhor/ExportModel/main/model/model.json';
export default {
  name: 'Home',

  data() {
    return {
      // store the promises of initialization
      streamPromise: null,
      modelPromise: null,
      // control the UI visibilities
      isVideoStreamReady: false,
      isModelReady: false,
      initFailMessage: '',
      // tfjs model related
      model: null,
      videoRatio: 1,
      resultWidth: 0,
      resultHeight: 0
    };
  },

  methods: {
    initWebcamStream() {
      // if the browser supports mediaDevices.getUserMedia API
      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        return navigator.mediaDevices.getUserMedia({
          audio: false,
          // don't capture audio
          video: {
            facingMode: 'environment'
          } // use the rear camera if there is

        }).then(stream => {
          // set <video> source as the webcam input
          let video = this.$refs.video;

          try {
            video.srcObject = stream;
          } catch (error) {
            // support older browsers
            video.src = URL.createObjectURL(stream);
          }
          /*
            model.detect uses tf.fromPixels to create tensors.
            tf.fromPixels api will get the <video> size from the width and height attributes,
              which means <video> width and height attributes needs to be set before called model.detect
              To make the <video> responsive, I get the initial video ratio when it's loaded (onloadedmetadata)
            Then addEventListener on resize, which will adjust the size but remain the ratio
            At last, resolve the Promise.
          */


          return new Promise((resolve, reject) => {
            // when video is loaded
            video.onloadedmetadata = () => {
              // calculate the video ratio
              this.videoRatio = video.offsetHeight / video.offsetWidth; // add event listener on resize to reset the <video> and <canvas> sizes

              window.addEventListener('resize', this.setResultSize); // set the initial size

              this.setResultSize();
              this.isVideoStreamReady = true;
              console.log('webcam stream initialized');
              resolve();
            };
          });
        }).catch(error => {
          console.log('failed to initialize webcam stream', error);
          throw error;
        });
      } else {
        return Promise.reject(new Error('Your browser does not support mediaDevices.getUserMedia API'));
      }
    },

    setResultSize() {
      // get the current browser window size
      let clientWidth = document.documentElement.clientWidth; // set max width as 600

      this.resultWidth = Math.min(640, clientWidth); // set the height according to the video ratio

      this.resultHeight = 640; // set <video> width and height

      /*
        Doesn't use vue binding :width and :height,
          because the initial value of resultWidth and resultHeight
          will affect the ratio got from the initWebcamStream()
      */

      let video = this.$refs.video;
      video.width = this.resultWidth;
      video.height = this.resultHeight;
    },

    loadCustomModel() {
      this.isModelReady = false; // load the model with loadGraphModel

      return loadGraphModel(MODEL_URL).then(model => {
        this.model = model;
        this.isModelReady = true;
        console.log('model loaded: ', model);
      }).catch(error => {
        console.log('failed to load the model', error);
        throw error;
      });
    },

    async detectObjects() {
      if (!this.isModelReady) return;
      const img = tf.browser.fromPixels(this.$refs.video);
      const resized = tf.image.resizeBilinear(img, [640, 640]);
      const casted = resized.cast('int32');
      const expanded = casted.expandDims(0);
      const obj = await this.model.executeAsync(expanded);
      console.log(obj[1].array());
      console.log(obj[4].array()); //check the size and assign to correct tensor

      for (let i = 0; i < 8; i++) {
        console.log('no');

        if (obj[i].size == 400 && obj[i].shape.length == 3) {
          var boxes = await obj[i].array();
          console.log(boxes);
        } else if (obj[i].size == 100 && obj[i].shape.length == 2) {
          var notsure = await obj[i].array();
          console.log();

          if (notsure[0][0] < 1) {
            var scores = await obj[i].array();
          } else if (notsure[0][0] >= 1) {
            var classes = await obj[i].array();
          }
        }
      } // const boxes = await obj[3].array()
      // const classes = await obj[4].array()
      // const scores = await obj[1].array()


      console.log(boxes);
      console.log(typeof obj[3].size);
      console.log(obj[3].shape.length);
      console.log(obj[4].size);
      console.log(obj[4].shape.length);
      console.log(obj[1].size);
      console.log(obj[1].shape.length); // this.renderPredictionBoxes(predictions[0].dataSync(), predictions[1].dataSync(), predictions[2].dataSync(), predictions[3].dataSync())

      const ctx = this.$refs.canvas.getContext("2d");
      requestAnimationFrame(() => {
        drawRect(boxes[0], classes[0], scores[0], 0.5, this.$refs.video.width, this.$refs.video.height, ctx);
      });
      tf.dispose(img);
      tf.dispose(resized);
      tf.dispose(casted);
      tf.dispose(expanded);
      tf.dispose(obj);
      ctx.clearRect(0, 0, this.$refs.canvas.width, this.$refs.canvas.height);
      console.log('cleared');
    },

    loadModelAndDetection() {
      this.modelPromise = this.loadCustomModel(); // wait for both stream and model promise finished then start detecting objects

      Promise.all([this.streamPromise, this.modelPromise]).then(() => {
        setInterval(this.detectObjects, 1000);
      }).catch(error => {
        console.log('Failed to init stream and/or model: ');
        this.initFailMessage = error;
      });
    }

  },

  mounted() {
    this.streamPromise = this.initWebcamStream();
    this.loadModelAndDetection();
  }

};"},{"version":3,"mappings":";AAcA;AACA;AACA;AACA;AACA;AAEA;EACAA,YADA;;EAGAC;IACA;MACA;MACAC,mBAFA;MAGAC,kBAHA;MAKA;MACAC,yBANA;MAOAC,mBAPA;MAQAC,mBARA;MAUA;MACAC,WAXA;MAaAC,aAbA;MAcAC,cAdA;MAeAC;IAfA;EAiBA,CArBA;;EAuBAC;IACAC;MACA;MACA;QACA;UACAC,YADA;UACA;UACAC;YAAAC;UAAA,CAFA,CAEA;;QAFA,GAIAC,IAJA,CAIAC;UACA;UACA;;UACA;YACAH;UACA,CAFA,CAEA;YACA;YACAA;UACA;UAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;UAEA;YACA;YACAA;cACA;cACA,yDAFA,CAGA;;cACAI,sDAJA,CAKA;;cACA;cAEA;cACAC;cACAC;YACA,CAXA;UAYA,CAdA;QAeA,CAtCA,EAuCAC,KAvCA,CAuCAC;UACAH;UACA;QACA,CA1CA;MA2CA,CA5CA,MA4CA;QACA;MACA;IACA,CAlDA;;IAoDAI;MACA;MACA,uDAFA,CAIA;;MACA,8CALA,CAMA;;MACA,wBAPA,CASA;;MACA;AACA;AACA;AACA;AACA;;MACA;MACAT;MACAA;IACA,CAtEA;;IAwEAU;MACA,0BADA,CAGA;;MACA,iCACAR,IADA,CACAT;QACA;QACA;QACAY;MACA,CALA,EAMAE,KANA,CAMAC;QACAH;QACA;MACA,CATA;IAUA,CAtFA;;IAwFA;MACA;MAEA;MACA;MACA;MACA;MACA;MACAA;MACAA,4BATA,CAUA;;MACA;QACAA;;QACA;UAEA;UACAA;QAEA,CALA,MAKA;UAEA;UACAA;;UAEA;YAEA;UACA,CAHA,MAGA;YACA;UACA;QACA;MACA,CA9BA,CAgCA;MACA;MACA;;;MACAA;MACAA;MACAA;MACAA;MACAA;MACAA;MACAA,iCAzCA,CA2CA;;MACA;MACAM;QAAAC;MAAA;MAEAC;MACAA;MACAA;MACAA;MACAA;MACAC;MACAT;IACA,CA9IA;;IAgJAU;MACA,2CADA,CAGA;;MACAC,qDACAd,IADA,CACA;QACAe;MACA,CAHA,EAGAV,KAHA,CAGAC;QACAH;QACA;MACA,CANA;IAOA;;EA3JA,CAvBA;;EAuLAa;IACA;IACA;EAEA;;AA3LA","names":["name","data","streamPromise","modelPromise","isVideoStreamReady","isModelReady","initFailMessage","model","videoRatio","resultWidth","resultHeight","methods","initWebcamStream","audio","video","facingMode","then","stream","window","console","resolve","catch","error","setResultSize","loadCustomModel","requestAnimationFrame","drawRect","tf","ctx","loadModelAndDetection","Promise","setInterval","mounted"],"sourceRoot":"src","sources":["Home.vue"],"sourcesContent":["<template>\r\n  <div id=\"Home\">\r\n    <h3 v-if=\"!isVideoStreamReady && !initFailMessage\">Initializing webcam stream ...</h3>\r\n    <h3 v-if=\"!isModelReady && !initFailMessage\">loading model ...</h3>\r\n    <h3 v-if=\"initFailMessage\">Failed to init stream and/or model - {{ initFailMessage }}</h3>\r\n\r\n    <div class=\"resultFrame\">\r\n      <video ref=\"video\" autoplay></video>\r\n      <canvas ref=\"canvas\" :width=\"resultWidth\" :height=\"resultHeight\"></canvas>\r\n    </div>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\nvar boxes;\r\nimport * as tf from '@tensorflow/tfjs'\r\nimport { loadGraphModel } from '@tensorflow/tfjs-converter'\r\nimport {drawRect} from \"./utilities\"; \r\nconst MODEL_URL = 'https://raw.githubusercontent.com/zbkhor/ExportModel/main/model/model.json'\r\n\r\nexport default {\r\n  name: 'Home',\r\n\r\n  data () {\r\n    return {\r\n      // store the promises of initialization\r\n      streamPromise: null,\r\n      modelPromise: null,\r\n\r\n      // control the UI visibilities\r\n      isVideoStreamReady: false,\r\n      isModelReady: false,\r\n      initFailMessage: '',\r\n\r\n      // tfjs model related\r\n      model: null,\r\n\r\n      videoRatio: 1,\r\n      resultWidth: 0,\r\n      resultHeight: 0\r\n    }\r\n  },\r\n\r\n  methods: {\r\n    initWebcamStream () {\r\n      // if the browser supports mediaDevices.getUserMedia API\r\n      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\r\n        return navigator.mediaDevices.getUserMedia({\r\n          audio: false, // don't capture audio\r\n          video: { facingMode: 'environment' } // use the rear camera if there is\r\n        })\r\n          .then(stream => {\r\n            // set <video> source as the webcam input\r\n            let video = this.$refs.video\r\n            try {\r\n              video.srcObject = stream\r\n            } catch (error) {\r\n              // support older browsers\r\n              video.src = URL.createObjectURL(stream)\r\n            }\r\n\r\n            /*\r\n              model.detect uses tf.fromPixels to create tensors.\r\n              tf.fromPixels api will get the <video> size from the width and height attributes,\r\n                which means <video> width and height attributes needs to be set before called model.detect\r\n\r\n              To make the <video> responsive, I get the initial video ratio when it's loaded (onloadedmetadata)\r\n              Then addEventListener on resize, which will adjust the size but remain the ratio\r\n              At last, resolve the Promise.\r\n            */\r\n            return new Promise((resolve, reject) => {\r\n              // when video is loaded\r\n              video.onloadedmetadata = () => {\r\n                // calculate the video ratio\r\n                this.videoRatio = video.offsetHeight / video.offsetWidth\r\n                // add event listener on resize to reset the <video> and <canvas> sizes\r\n                window.addEventListener('resize', this.setResultSize)\r\n                // set the initial size\r\n                this.setResultSize()\r\n\r\n                this.isVideoStreamReady = true\r\n                console.log('webcam stream initialized')\r\n                resolve()\r\n              }\r\n            })\r\n          })\r\n          .catch(error => {\r\n            console.log('failed to initialize webcam stream', error)\r\n            throw (error)\r\n          })\r\n      } else {\r\n        return Promise.reject(new Error('Your browser does not support mediaDevices.getUserMedia API'))\r\n      }\r\n    },\r\n    \r\n    setResultSize () {\r\n      // get the current browser window size\r\n      let clientWidth = document.documentElement.clientWidth\r\n\r\n      // set max width as 600\r\n      this.resultWidth = Math.min(640, clientWidth)\r\n      // set the height according to the video ratio\r\n      this.resultHeight = 640\r\n\r\n      // set <video> width and height\r\n      /*\r\n        Doesn't use vue binding :width and :height,\r\n          because the initial value of resultWidth and resultHeight\r\n          will affect the ratio got from the initWebcamStream()\r\n      */\r\n      let video = this.$refs.video\r\n      video.width = this.resultWidth\r\n      video.height = this.resultHeight\r\n    },\r\n\r\n    loadCustomModel () {\r\n      this.isModelReady = false\r\n\r\n      // load the model with loadGraphModel\r\n      return loadGraphModel(MODEL_URL)\r\n        .then((model) => {\r\n          this.model = model\r\n          this.isModelReady = true\r\n          console.log('model loaded: ', model)\r\n        })\r\n        .catch((error) => {\r\n          console.log('failed to load the model', error)\r\n          throw (error)\r\n        })\r\n    },\r\n    \r\n    async detectObjects () {\r\n      if (!this.isModelReady) return\r\n\r\n      const img = tf.browser.fromPixels(this.$refs.video)\r\n      const resized = tf.image.resizeBilinear(img, [640,640])\r\n      const casted = resized.cast('int32')\r\n      const expanded = casted.expandDims(0)\r\n      const obj = await this.model.executeAsync(expanded)\r\n      console.log(obj[1].array()) \r\n      console.log(obj[4].array())\r\n      //check the size and assign to correct tensor\r\n      for(let i = 0;i <8; i++){\r\n       console.log('no')\r\n       if (obj[i].size==400 && obj[i].shape.length==3){\r\n     \r\n        var boxes = await obj[i].array()\r\n        console.log(boxes)\r\n       \r\n       }else if (obj[i].size==100 && obj[i].shape.length==2){\r\n         \r\n          var notsure = await obj[i].array()\r\n          console.log()\r\n        \r\n          if (notsure[0][0] < 1){\r\n           \r\n           var scores = await obj[i].array()\r\n          }else if (notsure[0][0] >=1){\r\n            var classes = await obj[i].array()\r\n          }\r\n       }  \r\n      }\r\n      \r\n      // const boxes = await obj[3].array()\r\n      // const classes = await obj[4].array()\r\n      // const scores = await obj[1].array()\r\n      console.log(boxes)\r\n      console.log(typeof obj[3].size)\r\n      console.log(obj[3].shape.length)\r\n      console.log(obj[4].size)\r\n      console.log(obj[4].shape.length)\r\n      console.log(obj[1].size)\r\n      console.log(obj[1].shape.length)\r\n      \r\n      // this.renderPredictionBoxes(predictions[0].dataSync(), predictions[1].dataSync(), predictions[2].dataSync(), predictions[3].dataSync())\r\n      const ctx = this.$refs.canvas.getContext(\"2d\");\r\n      requestAnimationFrame(()=>{drawRect(boxes[0], classes[0], scores[0], 0.5, this.$refs.video.width, this.$refs.video.height, ctx)}); \r\n\r\n      tf.dispose(img)\r\n      tf.dispose(resized)\r\n      tf.dispose(casted)\r\n      tf.dispose(expanded)\r\n      tf.dispose(obj)\r\n      ctx.clearRect(0, 0, this.$refs.canvas.width, this.$refs.canvas.height);\r\n      console.log('cleared')\r\n    },\r\n\r\n    loadModelAndDetection () {\r\n      this.modelPromise = this.loadCustomModel()\r\n\r\n      // wait for both stream and model promise finished then start detecting objects\r\n      Promise.all([this.streamPromise, this.modelPromise])\r\n        .then(() => {\r\n          setInterval(this.detectObjects,1000)\r\n        }).catch((error) => {\r\n          console.log('Failed to init stream and/or model: ')\r\n          this.initFailMessage = error\r\n        })\r\n    },\r\n\r\n\r\n  },\r\n\r\n  mounted () {\r\n    this.streamPromise = this.initWebcamStream()\r\n    this.loadModelAndDetection()\r\n    \r\n  }\r\n}\r\n</script>\r\n\r\n<style lang=\"scss\">\r\nbody {\r\n  margin: 0;\r\n}\r\n\r\n.resultFrame {\r\n  display: grid;\r\n\r\n  video {\r\n    grid-area: 1 / 8 / 2 / 8;\r\n  }\r\n  canvas {\r\n    grid-area: 1 / 8 / 2 / 8;\r\n  }\r\n}\r\n</style>\r\n"]}]}