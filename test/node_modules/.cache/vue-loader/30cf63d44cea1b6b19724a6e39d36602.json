{"remainingRequest":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\vue-loader\\lib\\index.js??vue-loader-options!C:\\PPE_Detection\\tfjs-vue-example\\src\\Home.vue?vue&type=style&index=0&lang=scss&","dependencies":[{"path":"C:\\PPE_Detection\\tfjs-vue-example\\src\\Home.vue","mtime":1657615919664},{"path":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\css-loader\\index.js","mtime":1657169707846},{"path":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\vue-loader\\lib\\loaders\\stylePostLoader.js","mtime":1657169712985},{"path":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\postcss-loader\\src\\index.js","mtime":1657169710521},{"path":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\sass-loader\\lib\\loader.js","mtime":1657169710805},{"path":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\cache-loader\\dist\\cjs.js","mtime":1657169709851},{"path":"C:\\PPE_Detection\\tfjs-vue-example\\node_modules\\vue-loader\\lib\\index.js","mtime":1657169712686}],"contextDependencies":[],"result":["\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\r\nbody {\r\n  margin: 0;\r\n}\r\n\r\n.resultFrame {\r\n  display: grid;\r\n\r\n  video {\r\n    grid-area: 1 / 8 / 2 / 8;\r\n  }\r\n  canvas {\r\n    grid-area: 1 / 8 / 2 / 8;\r\n  }\r\n}\r\n",{"version":3,"sources":["Home.vue"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAoNA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA","file":"Home.vue","sourceRoot":"src","sourcesContent":["<template>\r\n  <div id=\"app\">\r\n    <h3 v-if=\"!isVideoStreamReady && !initFailMessage\">Initializing webcam stream ...</h3>\r\n    <h3 v-if=\"!isModelReady && !initFailMessage\">loading model ...</h3>\r\n    <h3 v-if=\"initFailMessage\">Failed to init stream and/or model - {{ initFailMessage }}</h3>\r\n\r\n    <div class=\"resultFrame\">\r\n      <video ref=\"video\" autoplay></video>\r\n      <canvas ref=\"canvas\" :width=\"resultWidth\" :height=\"resultHeight\"></canvas>\r\n    </div>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\nvar boxes;\r\nimport * as tf from '@tensorflow/tfjs'\r\nimport { loadGraphModel } from '@tensorflow/tfjs-converter'\r\nimport {drawRect} from \"./utilities\"; \r\nconst MODEL_URL = 'https://raw.githubusercontent.com/zbkhor/ExportModel/main/model/model.json'\r\n\r\nexport default {\r\n  name: 'app',\r\n\r\n  data () {\r\n    return {\r\n      // store the promises of initialization\r\n      streamPromise: null,\r\n      modelPromise: null,\r\n\r\n      // control the UI visibilities\r\n      isVideoStreamReady: false,\r\n      isModelReady: false,\r\n      initFailMessage: '',\r\n\r\n      // tfjs model related\r\n      model: null,\r\n\r\n      videoRatio: 1,\r\n      resultWidth: 0,\r\n      resultHeight: 0\r\n    }\r\n  },\r\n\r\n  methods: {\r\n    initWebcamStream () {\r\n      // if the browser supports mediaDevices.getUserMedia API\r\n      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\r\n        return navigator.mediaDevices.getUserMedia({\r\n          audio: false, // don't capture audio\r\n          video: { facingMode: 'environment' } // use the rear camera if there is\r\n        })\r\n          .then(stream => {\r\n            // set <video> source as the webcam input\r\n            let video = this.$refs.video\r\n            try {\r\n              video.srcObject = stream\r\n            } catch (error) {\r\n              // support older browsers\r\n              video.src = URL.createObjectURL(stream)\r\n            }\r\n\r\n            /*\r\n              model.detect uses tf.fromPixels to create tensors.\r\n              tf.fromPixels api will get the <video> size from the width and height attributes,\r\n                which means <video> width and height attributes needs to be set before called model.detect\r\n\r\n              To make the <video> responsive, I get the initial video ratio when it's loaded (onloadedmetadata)\r\n              Then addEventListener on resize, which will adjust the size but remain the ratio\r\n              At last, resolve the Promise.\r\n            */\r\n            return new Promise((resolve, reject) => {\r\n              // when video is loaded\r\n              video.onloadedmetadata = () => {\r\n                // calculate the video ratio\r\n                this.videoRatio = video.offsetHeight / video.offsetWidth\r\n                // add event listener on resize to reset the <video> and <canvas> sizes\r\n                window.addEventListener('resize', this.setResultSize)\r\n                // set the initial size\r\n                this.setResultSize()\r\n\r\n                this.isVideoStreamReady = true\r\n                console.log('webcam stream initialized')\r\n                resolve()\r\n              }\r\n            })\r\n          })\r\n          .catch(error => {\r\n            console.log('failed to initialize webcam stream', error)\r\n            throw (error)\r\n          })\r\n      } else {\r\n        return Promise.reject(new Error('Your browser does not support mediaDevices.getUserMedia API'))\r\n      }\r\n    },\r\n    \r\n    setResultSize () {\r\n      // get the current browser window size\r\n      let clientWidth = document.documentElement.clientWidth\r\n\r\n      // set max width as 600\r\n      this.resultWidth = Math.min(640, clientWidth)\r\n      // set the height according to the video ratio\r\n      this.resultHeight = 640\r\n\r\n      // set <video> width and height\r\n      /*\r\n        Doesn't use vue binding :width and :height,\r\n          because the initial value of resultWidth and resultHeight\r\n          will affect the ratio got from the initWebcamStream()\r\n      */\r\n      let video = this.$refs.video\r\n      video.width = this.resultWidth\r\n      video.height = this.resultHeight\r\n    },\r\n\r\n    loadCustomModel () {\r\n      this.isModelReady = false\r\n\r\n      // load the model with loadGraphModel\r\n      return loadGraphModel(MODEL_URL)\r\n        .then((model) => {\r\n          this.model = model\r\n          this.isModelReady = true\r\n          console.log('model loaded: ', model)\r\n        })\r\n        .catch((error) => {\r\n          console.log('failed to load the model', error)\r\n          throw (error)\r\n        })\r\n    },\r\n    \r\n    async detectObjects () {\r\n      if (!this.isModelReady) return\r\n\r\n      const img = tf.browser.fromPixels(this.$refs.video)\r\n      const resized = tf.image.resizeBilinear(img, [640,640])\r\n      const casted = resized.cast('int32')\r\n      const expanded = casted.expandDims(0)\r\n      const obj = await this.model.executeAsync(expanded)\r\n      console.log(obj[1].array()) \r\n      console.log(obj[4].array())\r\n      //check the size and assign to correct tensor\r\n      for(let i = 0;i <8; i++){\r\n       console.log('no')\r\n       if (obj[i].size==400 && obj[i].shape.length==3){\r\n     \r\n        var boxes = await obj[i].array()\r\n        console.log(boxes)\r\n       \r\n       }else if (obj[i].size==100 && obj[i].shape.length==2){\r\n         \r\n          var notsure = await obj[i].array()\r\n          console.log()\r\n        \r\n          if (notsure[0][0] < 1){\r\n           \r\n           var scores = await obj[i].array()\r\n          }else if (notsure[0][0] >=1){\r\n            var classes = await obj[i].array()\r\n          }\r\n       }  \r\n      }\r\n      \r\n      // const boxes = await obj[3].array()\r\n      // const classes = await obj[4].array()\r\n      // const scores = await obj[1].array()\r\n      console.log(boxes)\r\n      console.log(typeof obj[3].size)\r\n      console.log(obj[3].shape.length)\r\n      console.log(obj[4].size)\r\n      console.log(obj[4].shape.length)\r\n      console.log(obj[1].size)\r\n      console.log(obj[1].shape.length)\r\n      \r\n      // this.renderPredictionBoxes(predictions[0].dataSync(), predictions[1].dataSync(), predictions[2].dataSync(), predictions[3].dataSync())\r\n      const ctx = this.$refs.canvas.getContext(\"2d\");\r\n      requestAnimationFrame(()=>{drawRect(boxes[0], classes[0], scores[0], 0.5, this.$refs.video.width, this.$refs.video.height, ctx)}); \r\n\r\n      tf.dispose(img)\r\n      tf.dispose(resized)\r\n      tf.dispose(casted)\r\n      tf.dispose(expanded)\r\n      tf.dispose(obj)\r\n      ctx.clearRect(0, 0, this.$refs.canvas.width, this.$refs.canvas.height);\r\n      console.log('cleared')\r\n    },\r\n\r\n    loadModelAndDetection () {\r\n      this.modelPromise = this.loadCustomModel()\r\n\r\n      // wait for both stream and model promise finished then start detecting objects\r\n      Promise.all([this.streamPromise, this.modelPromise])\r\n        .then(() => {\r\n          setInterval(this.detectObjects,1000)\r\n        }).catch((error) => {\r\n          console.log('Failed to init stream and/or model: ')\r\n          this.initFailMessage = error\r\n        })\r\n    },\r\n\r\n\r\n  },\r\n\r\n  mounted () {\r\n    this.streamPromise = this.initWebcamStream()\r\n    this.loadModelAndDetection()\r\n    \r\n  }\r\n}\r\n</script>\r\n\r\n<style lang=\"scss\">\r\nbody {\r\n  margin: 0;\r\n}\r\n\r\n.resultFrame {\r\n  display: grid;\r\n\r\n  video {\r\n    grid-area: 1 / 8 / 2 / 8;\r\n  }\r\n  canvas {\r\n    grid-area: 1 / 8 / 2 / 8;\r\n  }\r\n}\r\n</style>\r\n"]}]}